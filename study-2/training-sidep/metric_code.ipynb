{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install sentence_transformers\n",
    "!pip install sacrebleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import numpy as np\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "import math\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "import nltk\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from sentence_transformers import SentenceTransformer, models, InputExample, losses, util\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "import torch\n",
    "import sacrebleu\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install Levenshtein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate correlation coefficients between codeFunctions and codeComment using a Levenshtein distance lower than two.\n",
    "def levenshtein_distance(codefunc, codesum):\n",
    "\tfrom Levenshtein import distance\n",
    "\t# split the strings into words\n",
    "\tcodefunc = codefunc.lower().split()\n",
    "\tcodesum = codesum.lower().split()\n",
    "\tsim_count = 0\n",
    "\t# count the similarity of words of codefunc to all words of codesum one by one\n",
    "\tfor sum in codesum:\n",
    "\t\tfor code in codefunc:\n",
    "\t\t\tif distance(sum, code) < 2:\n",
    "\t\t\t\tsim_count += 1\n",
    "\t\t\t\tbreak\n",
    "\tscore = sim_count / len(codesum) if len(codesum) > 0 else 0\n",
    "\treturn score\t\n",
    "\n",
    "def calculate_c_coefficients(dataframe):\n",
    "\t# Extract the columns\n",
    "\tcode = dataframe['codeFunctions'].astype(str).values\n",
    "\tcode_comments = dataframe['codeComment'].astype(str).values\n",
    "\n",
    "\t# Calculate the Levenshtein distance for each pair of code and comments\n",
    "\tlevenshtein_scores = []\n",
    "\tfor code_func, code_comment in zip(code, code_comments):\n",
    "\t\tlevenshtein_score = levenshtein_distance(code_func, code_comment)\n",
    "\t\tprint(\"c_coeff score\", levenshtein_score)\n",
    "\t\tlevenshtein_scores.append(levenshtein_score)\n",
    "\tdataframe['levenshtein_similarity'] = levenshtein_scores\n",
    "\treturn dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    df_data = pd.read_csv('/home/user/projects/prompt-project/SIDE_p/scripts_and_data/training_SIDE/evaluation_and_statistical_tests/data_with_all_metrics_scores_with-side.csv')\n",
    "    print(\"******************* Computing c_coeff SCORES *******************\\n\")\n",
    "    df_data = calculate_c_coefficients(df_data)\n",
    "    df_data.to_csv('/home/user/projects/prompt-project/SIDE_p/scripts_and_data/training_SIDE/evaluation_and_statistical_tests/c-coeff-test.csv')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\tmain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'response = client.embeddings.create(\\n    input=\"Your text string goes here\",\\n    model=\"text-embedding-3-small\"\\n)\\n\\nprint(response.data[0].embedding)'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import openai\n",
    "from openai import OpenAI\n",
    "# The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable\n",
    "# Set your OpenAI API key\n",
    "\n",
    "\n",
    "api_key = \"key\"\n",
    "client = OpenAI(api_key=api_key)\n",
    "\n",
    "'''response = client.embeddings.create(\n",
    "    input=\"Your text string goes here\",\n",
    "    model=\"text-embedding-3-small\"\n",
    ")\n",
    "\n",
    "print(response.data[0].embedding)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0  id                function_name  \\\n",
      "0           0   1  register_component_producer   \n",
      "1           1   2           process_in_batches   \n",
      "2           2   3              filter_property   \n",
      "3           3   4         _save_ontology_to_db   \n",
      "4           4   5        _build_merge_function   \n",
      "\n",
      "                                       codeFunctions  \\\n",
      "0  def register_component_producer(self, componen...   \n",
      "1  def process_in_batches(tx, query, data, batch_...   \n",
      "2  def filter_property(self, siid: int, piid: int...   \n",
      "3  def _save_ontology_to_db(self, ontology: \"Onto...   \n",
      "4  def _build_merge_function(self):\\n        \\n\\n...   \n",
      "\n",
      "                                     originalComment  \\\n",
      "0  Link a component ID to its producing atom for ...   \n",
      "1  Process data in batches and execute the given ...   \n",
      "2                           Filter property by piid.   \n",
      "3  Save graph ontology to a separate table with {...   \n",
      "4  Adds tracing metadata to the control message a...   \n",
      "\n",
      "                                         codeComment    BLEU_1  ROUGE_1_P  \\\n",
      "0  Registers a component producer with validation...  0.613636   0.307692   \n",
      "1  Processes data in specified batch sizes for ef...  0.605263   0.500000   \n",
      "2  Check if a property exists in the cached prope...  0.287671   0.083333   \n",
      "3  Saves an ontology to a database if it doesn't ...  0.693709   0.333333   \n",
      "4  Creates a merge function to add trace tagging ...  0.750000   0.428571   \n",
      "\n",
      "   ROUGE_W_R  CodeT5_plus_CS  BERTScore_R  SentenceBERT_CS  InferSent_CS  \\\n",
      "0   0.363636        0.619882     0.245792         0.602086      0.703805   \n",
      "1   0.555556        0.604006     0.509064         0.759491      0.793684   \n",
      "2   0.250000        0.649855    -0.006169         0.407021      0.481876   \n",
      "3   0.363636        0.650009     0.087214         0.488407      0.718535   \n",
      "4   0.454545        0.620476     0.318430         0.682117      0.809921   \n",
      "\n",
      "    C_Coeff  \n",
      "0  0.307692  \n",
      "1  0.400000  \n",
      "2  0.250000  \n",
      "3  0.545455  \n",
      "4  0.071429  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# Load the DataFrame\n",
    "df = pd.read_csv('/home/user/projects/prompt-project/SIDE_p/scripts_and_data/training_SIDE/evaluation_and_statistical_tests/benchmark-gpt-evaluation/gpt_generated_summaries_p2.csv')\n",
    "# Display the DataFrame\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id                function_name  \\\n",
      "0   1  register_component_producer   \n",
      "1   2           process_in_batches   \n",
      "2   3              filter_property   \n",
      "3   4         _save_ontology_to_db   \n",
      "4   5        _build_merge_function   \n",
      "\n",
      "                                       codeFunctions  \\\n",
      "0  def register_component_producer(self, componen...   \n",
      "1  def process_in_batches(tx, query, data, batch_...   \n",
      "2  def filter_property(self, siid: int, piid: int...   \n",
      "3  def _save_ontology_to_db(self, ontology: \"Onto...   \n",
      "4  def _build_merge_function(self):\\n        \\n\\n...   \n",
      "\n",
      "                                     originalComment  \\\n",
      "0  Link a component ID to its producing atom for ...   \n",
      "1  Process data in batches and execute the given ...   \n",
      "2                           Filter property by piid.   \n",
      "3  Save graph ontology to a separate table with {...   \n",
      "4  Adds tracing metadata to the control message a...   \n",
      "\n",
      "                                         codeComment    BLEU_1  ROUGE_1_P  \\\n",
      "0  Registers a component producer with validation...  0.613636   0.307692   \n",
      "1  Processes data in specified batch sizes for ef...  0.605263   0.500000   \n",
      "2  Check if a property exists in the cached prope...  0.287671   0.083333   \n",
      "3  Saves an ontology to a database if it doesn't ...  0.693709   0.333333   \n",
      "4  Creates a merge function to add trace tagging ...  0.750000   0.428571   \n",
      "\n",
      "   ROUGE_W_R  CodeT5_plus_CS  BERTScore_R  SentenceBERT_CS  InferSent_CS  \\\n",
      "0   0.363636        0.619882     0.245792         0.602086      0.703805   \n",
      "1   0.555556        0.604006     0.509064         0.759491      0.793684   \n",
      "2   0.250000        0.649855    -0.006169         0.407021      0.481876   \n",
      "3   0.363636        0.650009     0.087214         0.488407      0.718535   \n",
      "4   0.454545        0.620476     0.318430         0.682117      0.809921   \n",
      "\n",
      "    C_Coeff  \n",
      "0  0.307692  \n",
      "1  0.400000  \n",
      "2  0.250000  \n",
      "3  0.545455  \n",
      "4  0.071429  \n"
     ]
    }
   ],
   "source": [
    "df = df.drop(columns=['Unnamed: 0'])\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "############### GPT Embedding Similarity Calculation ####################\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import openai\n",
    "from openai import OpenAI\n",
    "\n",
    "# Set your OpenAI API key\n",
    "api_key = \"key\"\n",
    "client = OpenAI(api_key=api_key)\n",
    "input_file = '/home/user/projects/prompt-project/SIDE_p/scripts_and_data/training_SIDE/evaluation_and_statistical_tests/NEW-generation_from_3_models/CS-benchmark-Python-nohw.csv'\n",
    "# Load the DataFrame\n",
    "df = pd.read_csv(input_file)\n",
    "# Display the DataFrame\n",
    "#print(df.head())\n",
    "\n",
    "for idx, row in df.iterrows():\n",
    "    code = row['target']\n",
    "    code_comment = row['summary_postprocessed']\n",
    "    #print(\"Code Functions:\", code)\n",
    "    #print(\"Code Comment:\", code_comment)\n",
    "    # get the embedding for the code functions using OpenAI API\n",
    "    code_emb = client.embeddings.create(\n",
    "        input=code,\n",
    "        model=\"text-embedding-3-small\"\n",
    "        #model=\"text-embedding-3-large\"\n",
    "    )\n",
    "    #print(\"Code Embedding:\", code_emb.data[0].embedding)\n",
    "    # get the embedding for the code comments using OpenAI API\n",
    "    code_comment_emb = client.embeddings.create(\n",
    "        input=code_comment,\n",
    "        model=\"text-embedding-3-small\"\n",
    "        #model=\"text-embedding-3-large\"\n",
    "    )\n",
    "    #print(\"Code Comment Embedding:\", code_comment_emb.data[0].embedding)\n",
    "    # Calculate cosine similarity\n",
    "    code_embedding = code_emb.data[0].embedding\n",
    "    code_comment_embedding = code_comment_emb.data[0].embedding\n",
    "    similarity = np.dot(code_embedding, code_comment_embedding) / (np.linalg.norm(code_embedding) * np.linalg.norm(code_comment_embedding))\n",
    "    #print(\"Cosine Similarity:\", similarity)\n",
    "    # Save the similarity score in the DataFrame\n",
    "    df.at[idx, 'GPT_emb'] = similarity\n",
    "# Save the updated DataFrame to a same CSV file\n",
    "df.to_csv(input_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('/home/user/projects/prompt-project/SIDE_p/scripts_and_data/training_SIDE/evaluation_and_statistical_tests/benchmark-gpt-evaluation/gpt_annotation-500.csv')\n",
    "# rename column SIDE_emb to GPT_emb\n",
    "df.rename(columns={'SIDE_emb': 'GPT_emb'}, inplace=True)\n",
    "# save to same file\n",
    "df.to_csv('/home/user/projects/prompt-project/SIDE_p/scripts_and_data/training_SIDE/evaluation_and_statistical_tests/benchmark-gpt-evaluation/gpt_annotation-500.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read CSV\n",
    "input_file = '/home/user/projects/prompt-project/SIDE_p/scripts_and_data/training_SIDE/evaluation_and_statistical_tests/NEW-generation_from_3_models/CS-benchmark-Python-nohw.csv'\n",
    "df = pd.read_csv(input_file)\n",
    "\n",
    "# Fill missing values with 0.0 in predictor columns\n",
    "predictors = [\"BLEU_1\", \"ROUGE_1_P\", \"ROUGE_W_R\", \"CodeT5_plus_CS\", \"BERTScore_R\", \n",
    "              \"SentenceBERT_CS\", \"InferSent_CS\", \"SIDE_score\", \"C_Coeff\", \"GPT_emb\"]\n",
    "\n",
    "df[predictors] = df[predictors].fillna(0.0)\n",
    "\n",
    "# Save fixed file\n",
    "df.to_csv(input_file, index=False)\n",
    "\n",
    "print(\"Fixed! Missing values filled with 0.0\")\n",
    "print(f'Saved as: {input_file}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows in file1: 1184438\n",
      "Rows in file2: 540170\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV files\n",
    "csv1 = pd.read_csv('/home/user/projects/prompt-project/ICPC_REPLICATION_PACKAGE/Datasets/funcom/train.csv')\n",
    "csv2 = pd.read_csv('/home/user/projects/prompt-project/ICPC_REPLICATION_PACKAGE/Datasets/funcom/threshold_0_9/train_filtered_more_than_0_9.csv')\n",
    "\n",
    "# Print number of rows\n",
    "print(\"Rows in file1:\", len(csv1))\n",
    "print(\"Rows in file2:\", len(csv2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading CSV files...\n",
      "Base file shape: (230, 5)\n",
      "Source file shape: (230, 4)\n",
      "Replacing target column...\n",
      "Updated file saved as: base-SIDE-golden-test-results@1_updated.csv\n",
      "\n",
      "First 3 rows of updated file:\n",
      "   Unnamed: 0                                             target  \\\n",
      "0           0  <s>Trim each element in the given string array...   \n",
      "1           1  <s>Check whether the length of the given two b...   \n",
      "2           2  <s>Pop an abstract type from the output frame ...   \n",
      "\n",
      "                                  raw_predictions  correctly_predicted  \\\n",
      "0                 Trims the elements of an array.                    0   \n",
      "1  Tells if two byte arrays have the same length.                    0   \n",
      "2            Pops the last output from the stack.                    0   \n",
      "\n",
      "   SIDE_score  \n",
      "0    0.937041  \n",
      "1    0.955541  \n",
      "2    0.036964  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def replace_target_column():\n",
    "    \"\"\"\n",
    "    Replace the 'target' column in base-SIDE-golden-test-results@1.csv \n",
    "    with the 'target' column from CBLEU_codereval_inference_results.csv\n",
    "    \"\"\"\n",
    "    \n",
    "    # Read both CSV files\n",
    "    print(\"Reading CSV files...\")\n",
    "    base_file = pd.read_csv(\"/home/user/projects/prompt-project/codet5+/dataset/funcom-java/inference_results-SIDE/base-SIDE-golden-test-results@1.csv\")\n",
    "    source_file = pd.read_csv(\"/home/user/projects/prompt-project/codet5+/dataset/funcom-java/inference_results-SIDE/CBLEU_codereval_inference_results.csv\")\n",
    "    \n",
    "    print(f\"Base file shape: {base_file.shape}\")\n",
    "    print(f\"Source file shape: {source_file.shape}\")\n",
    "    \n",
    "    # Check if both files have the same number of rows\n",
    "    if len(base_file) != len(source_file):\n",
    "        print(f\"Warning: Files have different number of rows!\")\n",
    "        print(f\"Base file: {len(base_file)} rows\")\n",
    "        print(f\"Source file: {len(source_file)} rows\")\n",
    "        print(\"Using the minimum number of rows...\")\n",
    "        min_rows = min(len(base_file), len(source_file))\n",
    "        base_file = base_file.iloc[:min_rows]\n",
    "        source_file = source_file.iloc[:min_rows]\n",
    "    \n",
    "    # Replace the target column\n",
    "    print(\"Replacing target column...\")\n",
    "    base_file['target'] = source_file['target']\n",
    "    \n",
    "    # Save the modified file\n",
    "    output_filename = \"base-SIDE-golden-test-results@1_updated.csv\"\n",
    "    base_file.to_csv(output_filename, index=False)\n",
    "    print(f\"Updated file saved as: {output_filename}\")\n",
    "    \n",
    "    # Display first few rows to verify\n",
    "    print(\"\\nFirst 3 rows of updated file:\")\n",
    "    print(base_file.head(3))\n",
    "    \n",
    "    return base_file\n",
    "\n",
    "# Run the function\n",
    "if __name__ == \"__main__\":\n",
    "    updated_df = replace_target_column()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
